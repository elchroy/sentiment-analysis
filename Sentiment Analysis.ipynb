{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pdb import set_trace\n",
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from time import sleep\n",
    "# for i in range(1,20):\n",
    "#     stdout.write(\"\\r%d\" % i)\n",
    "#     sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open('./reviews.txt', mode='r')\n",
    "reviews = [ r[:-1].lower() for r in g.readlines() ]\n",
    "g.close()\n",
    "\n",
    "h = open('./labels.txt', mode='r')\n",
    "labels = [ r[:-1].upper() for r in h.readlines() ]\n",
    "h.close()\n",
    "\n",
    "reviews, labels = reviews[0:100], labels[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = set() # Store all the words in the reviews\n",
    "for review in reviews:\n",
    "    for word in review.split(' '):\n",
    "        all_words.add(word)\n",
    "\n",
    "word2index = {} # I'm using this to store the indices of all the words\n",
    "for i, word in enumerate(all_words):\n",
    "    word2index[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4450"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = len(all_words)\n",
    "input_vector = np.zeros((1, vocab_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert each review into a 74074 vector\n",
    "def get_review_vector(review, input_vector):\n",
    "    review = review.lower()\n",
    "    input_vector *= 0\n",
    "    for word in review.split(' '):\n",
    "        input_vector[0][word2index[word]] = 1\n",
    "    return input_vector[0][None, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_review_vector(reviews[1], input_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_value(label):\n",
    "    return 1 if label == \"POSITIVE\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_indices(review):\n",
    "    review_indices = set()\n",
    "    for word in review.split(' '):\n",
    "        review_indices.add(word2index[word])\n",
    "    return list(review_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hidden_layer(review_indices):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label_value(labels[0]), get_label_value(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.99\n",
    "training_split = int(split * len(reviews))\n",
    "\n",
    "training_data, training_label = reviews[0:training_split], labels[0:training_split]\n",
    "valid_data, valid_label = reviews[training_split:], labels[training_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(z):\n",
    "    return z * (1 - z)\n",
    "\n",
    "def relu(x):\n",
    "    x[x > 0] = x\n",
    "    x[x <= 0] = 0.001\n",
    "    return x\n",
    "\n",
    "def relu_deriv(x):\n",
    "    x[x > 0] = 1\n",
    "    x[x <= 0] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(output):\n",
    "    return 1 if output >= 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'zip' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-109e13692d9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mzipped_training_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mzipped_training_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_training_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzipped_training_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mreview_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_review_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.shuffle\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'zip' has no len()"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "hidden_1_size = 100\n",
    "hidden_2_size = 150\n",
    "batch_size = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "weights_1 = np.zeros((vocab_length, hidden_1_size)) # start with random values\n",
    "weights_2 = np.random.normal(0.0, 1.0, (hidden_1_size, hidden_2_size))\n",
    "weights_3 = np.random.normal(0.0, 1.0, (hidden_2_size, 1))\n",
    "\n",
    "for e in range(epochs):\n",
    "    training_losses = []\n",
    "    train_correct = 0\n",
    "    zipped_training_label = zip(training_data, training_label)\n",
    "    zipped_training_label = np.random.shuffle(zipped_training_label)\n",
    "    for review, label in zipped_training_label:\n",
    "        review_vector = get_review_vector(review, input_vector)\n",
    "        hidden_1_input = np.dot(review_vector, weights_1)\n",
    "        hidden_1_output = sigmoid(hidden_1_input)\n",
    "        \n",
    "        hidden_2_input = np.dot(hidden_1_output, weights_2)\n",
    "        hidden_2_output = sigmoid(hidden_2_input)\n",
    "        \n",
    "        final_layer_input = np.dot(hidden_2_output, weights_3)\n",
    "        final_layer_output = sigmoid(final_layer_input)\n",
    "        \n",
    "        if get_pred(final_layer_output) == get_label_value(label):\n",
    "            train_correct += 1\n",
    "        \n",
    "        output_error = final_layer_output - get_label_value(label)\n",
    "        output_error_delta = output_error * sigmoid_deriv(final_layer_output)\n",
    "        \n",
    "        hidden_2_error = output_error_delta * weights_3.T\n",
    "        hidden_2_error_delta = hidden_2_error * sigmoid_deriv(hidden_2_output)\n",
    "        \n",
    "        hidden_1_error = np.dot(hidden_2_error_delta, weights_2.T)\n",
    "        hidden_1_error_delta = hidden_1_error * sigmoid_deriv(hidden_1_output)\n",
    "        \n",
    "        weights_3_delta = output_error_delta.T * hidden_2_output\n",
    "        weights_2_delta = hidden_2_error_delta.T * hidden_1_output\n",
    "        weights_1_delta = hidden_1_error_delta.T * review_vector\n",
    "        \n",
    "        weights_3 -= lr * weights_3_delta.T\n",
    "        weights_2 -= lr * weights_2_delta.T\n",
    "        weights_1 -= lr * weights_1_delta.T\n",
    "        \n",
    "        training_losses.extend( (final_layer_output-get_label_value(label))**2 )\n",
    "    \n",
    "    training_loss_mean = np.mean(training_losses)\n",
    "\n",
    "    if e % 1 == 0:\n",
    "        valid_losses = []\n",
    "        val_correct = 0\n",
    "        for rev, lab in zip(valid_data, valid_label):\n",
    "            rev_vector = get_review_vector(rev, input_vector)\n",
    "            h_1_input = np.dot(rev_vector, weights_1)\n",
    "            h_1_output = sigmoid(h_1_input)\n",
    "            \n",
    "            h_2_input = np.dot(h_1_output, weights_2)\n",
    "            h_2_output = sigmoid(h_2_input)\n",
    "            \n",
    "            final_input = np.dot(h_2_output, weights_3)\n",
    "            final_output = sigmoid(final_input)\n",
    "            \n",
    "            if get_pred(final_output) == get_label_value(lab):\n",
    "                val_correct += 1\n",
    "                \n",
    "            \n",
    "            valid_losses.extend( (final_output-get_label_value(lab))**2 )\n",
    "        valid_loss_mean = np.mean(valid_losses)\n",
    "    \n",
    "        string = \"Epochs:{}/{} - Training Loss:{:.3f} - Validation Loss:{:.3f} - Training Acc:{:.3f}% - Validation Acc:{:.3f}%\".format(\n",
    "            e+1, epochs,\n",
    "            training_loss_mean, valid_loss_mean,\n",
    "            100*float(train_correct)/len(training_data),\n",
    "            100*float(val_correct)/len(valid_data)\n",
    "        )\n",
    "        # print(string)\n",
    "        stdout.write(\"\\r\" + string)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews[0], labels[0], get_label_value(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# epochs = 200\n",
    "# hidden_layer_size = 10\n",
    "\n",
    "\n",
    "# weights_1 = np.zeros((vocab_length, hidden_layer_size)) # start with random values\n",
    "# weights_2 = np.random.normal(0.0, 1.0, (hidden_layer_size, 1))\n",
    "\n",
    "# lr = 3e-6\n",
    "\n",
    "# for e in range(epochs):\n",
    "#     train_losses = []\n",
    "#     valid_losses = []\n",
    "#     training_acc = 0\n",
    "#     valid_acc = 0\n",
    "#     for review, label in zip(training_data, training_label):\n",
    "#         review_vector = get_review_vector(review, input_vector)\n",
    "#         hidden_layer_input = np.dot(review_vector, weights_1)\n",
    "        \n",
    "# #         hidden_layer_input = np.zeros((1, hidden_layer_size))\n",
    "# #         review_indices = get_review_indices(review)\n",
    "# #         for index in review_indices:\n",
    "# #             hidden_layer_input += weights_1[index]\n",
    "        \n",
    "#         hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "#         final_layer_input = np.dot(hidden_layer_output, weights_2)\n",
    "#         final_layer_output = sigmoid(final_layer_input)\n",
    "        \n",
    "# #         if e % 10 == 0:\n",
    "# #             print(final_layer_output[0][0], get_label_value(label))\n",
    "        \n",
    "#         output_error = final_layer_output - get_label_value(label)\n",
    "#         output_error_delta = output_error * sigmoid_deriv(final_layer_output)\n",
    "\n",
    "#         hidden_error = output_error_delta * weights_2.T\n",
    "#         hidden_error_delta = hidden_error * sigmoid_deriv(hidden_layer_output)\n",
    "\n",
    "#         weights_2_delta = output_error_delta * hidden_layer_output\n",
    "#         weights_1_delta = hidden_error_delta.T * review_vector\n",
    "\n",
    "#         # Update weights\n",
    "#         weights_2 -= lr * weights_2_delta.T\n",
    "#         weights_1 -= lr * weights_1_delta.T # remove\n",
    "        \n",
    "# #         for index in review_indices:\n",
    "# #             weights_1[index] += lr * hidden_error_delta[0]\n",
    "        \n",
    "#         train_loss = np.abs(output_error)\n",
    "#         train_losses.append(train_loss[0][0])\n",
    "# #         print(train_loss, 'herere')\n",
    "        \n",
    "#         if final_layer_output[0][0] >= 0.5 and get_label_value(label) == 1:\n",
    "#             training_acc += 1\n",
    "#         elif final_layer_output[0][0] < 0.5 and get_label_value(label) == 0:\n",
    "#             training_acc += 1\n",
    "            \n",
    "    \n",
    "#     else:\n",
    "#         for v_review, v_label in zip(valid_data, valid_label):\n",
    "            \n",
    "#             review_vector = get_review_vector(v_review, input_vector)\n",
    "#             hidden_input = np.dot(review_vector, weights_1)\n",
    "#             hidden_layer = sigmoid(hidden_input)\n",
    "#             final_layer = sigmoid(np.dot(hidden_layer, weights_2))\n",
    "            \n",
    "#             valid_loss = np.abs(get_label_value(v_label) - final_layer)\n",
    "#             valid_losses.append(valid_loss[0][0])\n",
    "            \n",
    "#             if final_layer[0][0] >= 0.5 and get_label_value(v_label) == 1:\n",
    "#                 valid_acc += 1\n",
    "#             elif final_layer[0][0] < 0.5 and get_label_value(v_label) == 0:\n",
    "#                 valid_acc += 1\n",
    "            \n",
    "# #             if valid_loss < 0.5:\n",
    "# #                 valid_acc += 1\n",
    "# #     accuracy = 100 * float(training_acc)/len(training_data)\n",
    "#     if e % 1 == 0:\n",
    "#         string = \"Epoch: {}/{} ... Accuracy: {}/{}\".format(e+1, epochs, valid_acc, len(valid_data))\n",
    "#         stdout.write(\"\\r\" + string)\n",
    "#     stdout.flush()\n",
    "    \n",
    "# #     if e % 1 == 0:\n",
    "# #         string = \"Epoch: {}/{} ... Accuracy: {}/{} ... \".format(e+1, epochs, training_acc, len(training_data))\n",
    "# #         stdout.write(\"\\r\" + string)\n",
    "# #     stdout.flush()\n",
    "\n",
    "# #     print(\"Training Accuracy: {}% ... Validation Accuracy\".format(accuracy, valid_acc, len(valid_data)))\n",
    "# #     print(\"Training Loss: {:.6f} ... Validation Loss: {:.6f}\".format(np.mean(train_losses), np.mean(valid_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### review_vector, get_label_value(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
